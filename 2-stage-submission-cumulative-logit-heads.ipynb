{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14f3b8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:57:52.166403Z",
     "iopub.status.busy": "2024-09-30T16:57:52.165534Z",
     "iopub.status.idle": "2024-09-30T17:00:52.322229Z",
     "shell.execute_reply": "2024-09-30T17:00:52.321308Z"
    },
    "papermill": {
     "duration": 180.17225,
     "end_time": "2024-09-30T17:00:52.324529",
     "exception": false,
     "start_time": "2024-09-30T16:57:52.152279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "dpkg-preconfigure: unable to re-open stdin: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package liblzma-dev:amd64.\r\n",
      "(Reading database ... 123110 files and directories currently installed.)\r\n",
      "Preparing to unpack .../liblzma-dev_5.2.5-2ubuntu1_amd64.deb ...\r\n",
      "Unpacking liblzma-dev:amd64 (5.2.5-2ubuntu1) ...\r\n",
      "Setting up liblzma-dev:amd64 (5.2.5-2ubuntu1) ...\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "dpkg-preconfigure: unable to re-open stdin: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libunwind-dev:amd64.\r\n",
      "(Reading database ... 123150 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libunwind-dev_1.3.2-2build2.1_amd64.deb ...\r\n",
      "Unpacking libunwind-dev:amd64 (1.3.2-2build2.1) ...\r\n",
      "Setting up libunwind-dev:amd64 (1.3.2-2build2.1) ...\r\n",
      "Processing triggers for man-db (2.10.2-1) ...\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"apt -q -qq install -y /kaggle/input/rsna_2024_o3d_color_vox/other/default/7/liblzma-dev_5.2.5-2ubuntu1_amd64.deb\")\n",
    "os.system(\"apt -q -qq install -y /kaggle/input/rsna_2024_o3d_color_vox/other/default/7/libunwind-dev_1.3.2-2build2.1_amd64.deb\")\n",
    "\n",
    "os.system(\"cp /usr/lib/x86_64-linux-gnu/libunwind.so /usr/lib/x86_64-linux-gnu/libunwind.so.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2f4d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:00:52.350482Z",
     "iopub.status.busy": "2024-09-30T17:00:52.350119Z",
     "iopub.status.idle": "2024-09-30T17:03:08.238951Z",
     "shell.execute_reply": "2024-09-30T17:03:08.237728Z"
    },
    "papermill": {
     "duration": 135.916727,
     "end_time": "2024-09-30T17:03:08.253751",
     "exception": false,
     "start_time": "2024-09-30T17:00:52.337024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: typer 0.12.3 does not provide the extra 'all'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet /kaggle/input/timm_3d_deps/other/initial/10/pydicom/pydicom/pydicom-2.4.4-py3-none-any.whl\n",
    "%pip install timm_3d --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/timm_3d/\n",
    "%pip install torchio --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/torchio/\n",
    "%pip install itk --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/itk/itk\n",
    "%pip install skorch --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/skorch/skorch\n",
    "%pip install spacecutter --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/spacecutter/\n",
    "%pip install pgzip --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/pgzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74081152",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:03:08.282145Z",
     "iopub.status.busy": "2024-09-30T17:03:08.281213Z",
     "iopub.status.idle": "2024-09-30T17:04:11.413180Z",
     "shell.execute_reply": "2024-09-30T17:04:11.412019Z"
    },
    "papermill": {
     "duration": 63.161598,
     "end_time": "2024-09-30T17:04:11.428045",
     "exception": false,
     "start_time": "2024-09-30T17:03:08.266447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install open3d --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/open3d/\n",
    "%pip uninstall -y --quiet open3d\n",
    "%pip install --quiet /kaggle/input/rsna_2024_o3d_color_vox/other/default/7/open3d_cpu-0.18.0-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adecdb1a",
   "metadata": {
    "papermill": {
     "duration": 0.013569,
     "end_time": "2024-09-30T17:04:11.454246",
     "exception": false,
     "start_time": "2024-09-30T17:04:11.440677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Stage 1: Predict keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4caa267e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:11.481793Z",
     "iopub.status.busy": "2024-09-30T17:04:11.481407Z",
     "iopub.status.idle": "2024-09-30T17:04:29.932058Z",
     "shell.execute_reply": "2024-09-30T17:04:29.930727Z"
    },
    "papermill": {
     "duration": 18.467263,
     "end_time": "2024-09-30T17:04:29.934259",
     "exception": false,
     "start_time": "2024-09-30T17:04:11.466996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Detection Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spinenet/SpineNet/spinenet/models/vfr.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(latest_pt, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading model trained for 436 epochs...\n",
      "Loading Appearance Model...\n",
      "==> Loading model trained for 188 epochs...\n",
      "Loading Context Model...\n",
      "==> Loading model trained for 17 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spinenet/SpineNet/spinenet/models/appearance.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(latest_pt, map_location=\"cpu\")\n",
      "/kaggle/input/spinenet/SpineNet/spinenet/models/context.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(latest_pt, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Grading Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spinenet/SpineNet/spinenet/models/grading.py:333: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(latest_pt, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading model trained for 2 epochs...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "sys.path.insert(0, '/kaggle/input/spinenet/SpineNet')\n",
    "import spinenet\n",
    "from spinenet import SpineNet, download_example_scan\n",
    "from spinenet.io import load_dicoms_from_folder\n",
    "\n",
    "spnt = SpineNet(device='cuda:0', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae19c2bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:29.964158Z",
     "iopub.status.busy": "2024-09-30T17:04:29.963107Z",
     "iopub.status.idle": "2024-09-30T17:04:29.968621Z",
     "shell.execute_reply": "2024-09-30T17:04:29.967791Z"
    },
    "papermill": {
     "duration": 0.022076,
     "end_time": "2024-09-30T17:04:29.970508",
     "exception": false,
     "start_time": "2024-09-30T17:04:29.948432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LEVELS = [\"L1\", \"L2\", \"L3\", \"L4\", \"L5\", \"S1\"]\n",
    "COLORS = {\n",
    "    \"L1\": \"red\",\n",
    "    \"L2\": \"blue\",\n",
    "    \"L3\": \"green\",\n",
    "    \"L4\": \"yellow\",\n",
    "    \"L5\": \"white\",\n",
    "    \"S1\": \"purple\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a11934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:29.999294Z",
     "iopub.status.busy": "2024-09-30T17:04:29.998905Z",
     "iopub.status.idle": "2024-09-30T17:04:30.003444Z",
     "shell.execute_reply": "2024-09-30T17:04:30.002557Z"
    },
    "papermill": {
     "duration": 0.021327,
     "end_time": "2024-09-30T17:04:30.005484",
     "exception": false,
     "start_time": "2024-09-30T17:04:29.984157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_descs_path = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\"\n",
    "test_images_path = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e43ce7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:30.034362Z",
     "iopub.status.busy": "2024-09-30T17:04:30.033955Z",
     "iopub.status.idle": "2024-09-30T17:04:30.062106Z",
     "shell.execute_reply": "2024-09-30T17:04:30.061081Z"
    },
    "papermill": {
     "duration": 0.045189,
     "end_time": "2024-09-30T17:04:30.064167",
     "exception": false,
     "start_time": "2024-09-30T17:04:30.018978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44036939</td>\n",
       "      <td>2828203845</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44036939</td>\n",
       "      <td>3481971518</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44036939</td>\n",
       "      <td>3844393089</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id   series_id series_description\n",
       "0  44036939  2828203845        Sagittal T1\n",
       "1  44036939  3481971518           Axial T2\n",
       "2  44036939  3844393089   Sagittal T2/STIR"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_descs = pd.read_csv(test_descs_path)\n",
    "test_descs_filtered = test_descs[test_descs[\"series_description\"] == \"Sagittal T1\"]\n",
    "test_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d0094fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:30.094493Z",
     "iopub.status.busy": "2024-09-30T17:04:30.093614Z",
     "iopub.status.idle": "2024-09-30T17:04:30.099871Z",
     "shell.execute_reply": "2024-09-30T17:04:30.099016Z"
    },
    "papermill": {
     "duration": 0.023498,
     "end_time": "2024-09-30T17:04:30.101929",
     "exception": false,
     "start_time": "2024-09-30T17:04:30.078431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_centers(data):\n",
    "    centers = {}\n",
    "    for item in data:\n",
    "        level = item[\"predicted_label\"]\n",
    "        if level in LEVELS:\n",
    "            average_polygon = item[\"average_polygon\"]\n",
    "            centroid_x = np.mean(average_polygon[:, 0])\n",
    "            centroid_y = np.mean(average_polygon[:, 1])\n",
    "            centroid_z = item[\"slice_nos\"][len(item[\"slice_nos\"])//2]\n",
    "            centers[level] = (centroid_x, centroid_y, centroid_z)\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "062cb0e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:30.131562Z",
     "iopub.status.busy": "2024-09-30T17:04:30.130844Z",
     "iopub.status.idle": "2024-09-30T17:04:30.135572Z",
     "shell.execute_reply": "2024-09-30T17:04:30.134704Z"
    },
    "papermill": {
     "duration": 0.021734,
     "end_time": "2024-09-30T17:04:30.137454",
     "exception": false,
     "start_time": "2024-09-30T17:04:30.115720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "centers_per_study = {\n",
    "    \"study_id\": [],\n",
    "    \"series_id\": [],\n",
    "    \"x\": [],\n",
    "    \"y\": [],\n",
    "    \"instance_number\": [],\n",
    "    \"level\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22ad7cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:30.167245Z",
     "iopub.status.busy": "2024-09-30T17:04:30.166313Z",
     "iopub.status.idle": "2024-09-30T17:04:37.286143Z",
     "shell.execute_reply": "2024-09-30T17:04:37.285090Z"
    },
    "papermill": {
     "duration": 7.137464,
     "end_time": "2024-09-30T17:04:37.288676",
     "exception": false,
     "start_time": "2024-09-30T17:04:30.151212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in test_descs_filtered.iterrows():\n",
    "    scan = load_dicoms_from_folder(f\"{test_images_path}/{row['study_id']}/{row['series_id']}\", require_extensions=False)\n",
    "    num_slices = scan.volume.shape[-1]\n",
    "\n",
    "    vert_dicts = spnt.detect_vb(scan.volume, scan.pixel_spacing)\n",
    "    centers = calculate_centers(vert_dicts)\n",
    "    \n",
    "    for level in centers:\n",
    "        centers_per_study[\"study_id\"].append(row['study_id'])\n",
    "        centers_per_study[\"series_id\"].append(row['series_id'])\n",
    "        centers_per_study[\"level\"].append(level)\n",
    "        \n",
    "        centers_per_study[\"x\"].append(centers[level][0])\n",
    "        centers_per_study[\"y\"].append(centers[level][1])\n",
    "        centers_per_study[\"instance_number\"].append(centers[level][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c305c95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:37.318819Z",
     "iopub.status.busy": "2024-09-30T17:04:37.318454Z",
     "iopub.status.idle": "2024-09-30T17:04:37.331588Z",
     "shell.execute_reply": "2024-09-30T17:04:37.330631Z"
    },
    "papermill": {
     "duration": 0.030735,
     "end_time": "2024-09-30T17:04:37.333912",
     "exception": false,
     "start_time": "2024-09-30T17:04:37.303177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44036939</td>\n",
       "      <td>2828203845</td>\n",
       "      <td>335.785366</td>\n",
       "      <td>154.553153</td>\n",
       "      <td>10</td>\n",
       "      <td>L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44036939</td>\n",
       "      <td>2828203845</td>\n",
       "      <td>304.148934</td>\n",
       "      <td>226.185392</td>\n",
       "      <td>11</td>\n",
       "      <td>L2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44036939</td>\n",
       "      <td>2828203845</td>\n",
       "      <td>272.576395</td>\n",
       "      <td>293.824498</td>\n",
       "      <td>13</td>\n",
       "      <td>L3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44036939</td>\n",
       "      <td>2828203845</td>\n",
       "      <td>248.552402</td>\n",
       "      <td>365.867719</td>\n",
       "      <td>14</td>\n",
       "      <td>L4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44036939</td>\n",
       "      <td>2828203845</td>\n",
       "      <td>253.116013</td>\n",
       "      <td>451.840578</td>\n",
       "      <td>14</td>\n",
       "      <td>L5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44036939</td>\n",
       "      <td>2828203845</td>\n",
       "      <td>302.432602</td>\n",
       "      <td>525.408792</td>\n",
       "      <td>14</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id   series_id           x           y  instance_number level\n",
       "0  44036939  2828203845  335.785366  154.553153               10    L1\n",
       "1  44036939  2828203845  304.148934  226.185392               11    L2\n",
       "2  44036939  2828203845  272.576395  293.824498               13    L3\n",
       "3  44036939  2828203845  248.552402  365.867719               14    L4\n",
       "4  44036939  2828203845  253.116013  451.840578               14    L5\n",
       "5  44036939  2828203845  302.432602  525.408792               14    S1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_per_study = pd.DataFrame.from_dict(centers_per_study)\n",
    "centers_per_study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9496a",
   "metadata": {
    "papermill": {
     "duration": 0.013843,
     "end_time": "2024-09-30T17:04:37.362176",
     "exception": false,
     "start_time": "2024-09-30T17:04:37.348333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Stage 1.5: Dump out bounding boxes csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18609c06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:37.391832Z",
     "iopub.status.busy": "2024-09-30T17:04:37.391206Z",
     "iopub.status.idle": "2024-09-30T17:04:37.397841Z",
     "shell.execute_reply": "2024-09-30T17:04:37.396937Z"
    },
    "papermill": {
     "duration": 0.023675,
     "end_time": "2024-09-30T17:04:37.399759",
     "exception": false,
     "start_time": "2024-09-30T17:04:37.376084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_coords_to_patient(x, y, dicom_slice):            \n",
    "    dX, dY = dicom_slice.PixelSpacing\n",
    "    \n",
    "    X = np.array(list(dicom_slice.ImageOrientationPatient[:3]) + [0]) * dY\n",
    "    Y = np.array(list(dicom_slice.ImageOrientationPatient[3:]) + [0]) * dX\n",
    "\n",
    "    S = np.array(list(dicom_slice.ImagePositionPatient) + [1])\n",
    "\n",
    "    transform_matrix = np.array([Y, X, np.zeros(len(X)), S]).T\n",
    "    # transform_matrix = transform_matrix @ transform_matrix_factor\n",
    "\n",
    "    return (transform_matrix @ np.array([y, x, 0, 1]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138d173f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:37.429541Z",
     "iopub.status.busy": "2024-09-30T17:04:37.428663Z",
     "iopub.status.idle": "2024-09-30T17:04:37.463662Z",
     "shell.execute_reply": "2024-09-30T17:04:37.462645Z"
    },
    "papermill": {
     "duration": 0.052084,
     "end_time": "2024-09-30T17:04:37.465746",
     "exception": false,
     "start_time": "2024-09-30T17:04:37.413662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44036939</td>\n",
       "      <td>L1</td>\n",
       "      <td>20.724218</td>\n",
       "      <td>44.669312</td>\n",
       "      <td>99.955032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44036939</td>\n",
       "      <td>L2</td>\n",
       "      <td>16.510600</td>\n",
       "      <td>32.805650</td>\n",
       "      <td>73.256503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44036939</td>\n",
       "      <td>L3</td>\n",
       "      <td>9.367907</td>\n",
       "      <td>20.965948</td>\n",
       "      <td>48.189862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44036939</td>\n",
       "      <td>L4</td>\n",
       "      <td>5.147208</td>\n",
       "      <td>11.956951</td>\n",
       "      <td>21.337373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44036939</td>\n",
       "      <td>L5</td>\n",
       "      <td>3.686905</td>\n",
       "      <td>13.668305</td>\n",
       "      <td>-10.869371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44036939</td>\n",
       "      <td>S1</td>\n",
       "      <td>2.437303</td>\n",
       "      <td>32.162026</td>\n",
       "      <td>-38.429146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id level          x          y          z\n",
       "0  44036939    L1  20.724218  44.669312  99.955032\n",
       "1  44036939    L2  16.510600  32.805650  73.256503\n",
       "2  44036939    L3   9.367907  20.965948  48.189862\n",
       "3  44036939    L4   5.147208  11.956951  21.337373\n",
       "4  44036939    L5   3.686905  13.668305 -10.869371\n",
       "5  44036939    S1   2.437303  32.162026 -38.429146"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydicom import dcmread\n",
    "\n",
    "test_images_basepath = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images\"\n",
    "\n",
    "patient_coords_dict = {\n",
    "    \"study_id\": [],\n",
    "    \"level\": [],\n",
    "    \"x\": [],\n",
    "    \"y\": [],\n",
    "    \"z\": []\n",
    "}\n",
    "\n",
    "for index, group in centers_per_study.groupby(\"study_id\"):\n",
    "    for row_index, row in group.iterrows():\n",
    "        dicom_slice_path = f\"{test_images_basepath}/{row['study_id']}/{row['series_id']}/{row['instance_number']}.dcm\"\n",
    "        dicom_slice = dcmread(dicom_slice_path)\n",
    "        coords = convert_coords_to_patient(row['x'], row['y'], dicom_slice)\n",
    "        \n",
    "        patient_coords_dict[\"study_id\"].append(row['study_id'])\n",
    "        patient_coords_dict[\"level\"].append(row['level'])\n",
    "        patient_coords_dict[\"x\"].append(coords[0])\n",
    "        patient_coords_dict[\"y\"].append(coords[1])\n",
    "        patient_coords_dict[\"z\"].append(coords[2])\n",
    "    \n",
    "patient_coords = pd.DataFrame.from_dict(patient_coords_dict)\n",
    "patient_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d560a192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:37.496398Z",
     "iopub.status.busy": "2024-09-30T17:04:37.495565Z",
     "iopub.status.idle": "2024-09-30T17:04:37.535340Z",
     "shell.execute_reply": "2024-09-30T17:04:37.534300Z"
    },
    "papermill": {
     "duration": 0.057831,
     "end_time": "2024-09-30T17:04:37.538106",
     "exception": false,
     "start_time": "2024-09-30T17:04:37.480275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>level</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>z_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>z_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44036939</td>\n",
       "      <td>l1_L2</td>\n",
       "      <td>-20.229776</td>\n",
       "      <td>21.325889</td>\n",
       "      <td>63.163957</td>\n",
       "      <td>57.464594</td>\n",
       "      <td>90.588355</td>\n",
       "      <td>110.047577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44036939</td>\n",
       "      <td>l2_L3</td>\n",
       "      <td>-29.742724</td>\n",
       "      <td>8.676290</td>\n",
       "      <td>37.003153</td>\n",
       "      <td>55.621231</td>\n",
       "      <td>81.964284</td>\n",
       "      <td>84.443213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44036939</td>\n",
       "      <td>l3_L4</td>\n",
       "      <td>-31.575526</td>\n",
       "      <td>0.925460</td>\n",
       "      <td>11.516468</td>\n",
       "      <td>46.090641</td>\n",
       "      <td>65.091910</td>\n",
       "      <td>58.010767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44036939</td>\n",
       "      <td>l4_L5</td>\n",
       "      <td>-38.062350</td>\n",
       "      <td>-1.812389</td>\n",
       "      <td>-13.090067</td>\n",
       "      <td>46.896464</td>\n",
       "      <td>68.745666</td>\n",
       "      <td>23.558069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44036939</td>\n",
       "      <td>l5_S1</td>\n",
       "      <td>-46.412285</td>\n",
       "      <td>0.146727</td>\n",
       "      <td>-56.241432</td>\n",
       "      <td>52.536494</td>\n",
       "      <td>86.248336</td>\n",
       "      <td>6.942915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id  level      x_min      y_min      z_min      x_max      y_max  \\\n",
       "0  44036939  l1_L2 -20.229776  21.325889  63.163957  57.464594  90.588355   \n",
       "1  44036939  l2_L3 -29.742724   8.676290  37.003153  55.621231  81.964284   \n",
       "2  44036939  l3_L4 -31.575526   0.925460  11.516468  46.090641  65.091910   \n",
       "3  44036939  l4_L5 -38.062350  -1.812389 -13.090067  46.896464  68.745666   \n",
       "4  44036939  l5_S1 -46.412285   0.146727 -56.241432  52.536494  86.248336   \n",
       "\n",
       "        z_max  \n",
       "0  110.047577  \n",
       "1   84.443213  \n",
       "2   58.010767  \n",
       "3   23.558069  \n",
       "4    6.942915  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_bounding_boxes_dict = {\n",
    "    \"study_id\": [],\n",
    "    \"level\": [],\n",
    "    \"x_min\": [],\n",
    "    \"y_min\": [],\n",
    "    \"z_min\": [],\n",
    "    \"x_max\": [],\n",
    "    \"y_max\": [],\n",
    "    \"z_max\": [],\n",
    "}\n",
    "\n",
    "for index, group in patient_coords.groupby(\"study_id\"):\n",
    "    ordered_group = group.sort_values(by=\"level\", ascending=True)\n",
    "    if len(ordered_group) != 6:\n",
    "        continue\n",
    "    for level_index in range(5):\n",
    "        patient_bounding_boxes_dict[\"study_id\"].append(ordered_group['study_id'].iloc[0])\n",
    "        level_label = ordered_group['level'].iloc[level_index].lower() + \"_\" + ordered_group['level'].iloc[level_index + 1] \n",
    "        patient_bounding_boxes_dict[\"level\"].append(level_label)\n",
    "        \n",
    "        # Middle vertebra points\n",
    "        pt_0 = np.array(ordered_group.iloc[level_index][[\"x\", \"y\", \"z\"]])\n",
    "        pt_1 = np.array(ordered_group.iloc[level_index + 1][[\"x\", \"y\", \"z\"]])\n",
    "        \n",
    "        # Distance vector to the next vertebra\n",
    "        d_vec = np.array(pt_0 - pt_1)\n",
    "        d_size = np.linalg.norm(d_vec)\n",
    "        d_unit = d_vec / d_size\n",
    "        \n",
    "        \n",
    "        # Get a pair of orthogonal vectors to find x and y boundary candidates\n",
    "        orth_1 = np.random.randn(3).astype(np.float64)\n",
    "        orth_1 = orth_1 - orth_1.dot(d_unit) * d_unit\n",
    "        orth_1 = orth_1 / np.linalg.norm(orth_1)\n",
    "        \n",
    "        orth_1 = orth_1.astype(np.float64)\n",
    "        d_unit = d_unit.astype(np.float64)\n",
    "        \n",
    "        orth_2 = np.cross(orth_1, d_unit)\n",
    "        orth_2 = orth_2.astype(np.float64)\n",
    "        \n",
    "        orth_1 *= d_size\n",
    "        orth_2 *= d_size\n",
    "        \n",
    "        # Get candidate points (10 of them, 2 per orthogonal per each vertebra center, and the centers themselves)\n",
    "        c_pts = np.array([pt - vec for pt in (pt_0, pt_1) for vec in (orth_1, orth_2)] + \n",
    "                         [pt + vec for pt in (pt_0, pt_1) for vec in (orth_1, orth_2)] +\n",
    "                         [pt_0, pt_1])\n",
    "        \n",
    "        # x_min and x_max are just the min and max from all this\n",
    "        x_min = np.min(c_pts[:, 0])\n",
    "        x_max = np.max(c_pts[:, 0])\n",
    "        \n",
    "        x_delta = x_max - x_min\n",
    "        x_min -= x_delta * 0.25\n",
    "        x_max += x_delta * 0.25\n",
    "        \n",
    "        # y_max is going to be over the center ys\n",
    "        # And we're going to get y_min by getting y_min over c_pts and then extending the y_min over center ys\n",
    "        c_pts_y_min = np.min(c_pts[:, 1])\n",
    "        c_pts_y_max = np.max(c_pts[:, 1])\n",
    "\n",
    "        y_max = max(pt_0[1], pt_1[1])\n",
    "        y_min = min(pt_0[1], pt_1[1])\n",
    "        \n",
    "        y_max += abs(c_pts_y_max - y_max) * 2\n",
    "        y_min -= abs(c_pts_y_min - y_min) / 2\n",
    "        \n",
    "        # z_max and z_min will be the same as x_min and x_max\n",
    "        z_min = np.min(c_pts[:, 2])\n",
    "        z_max = np.max(c_pts[:, 2])    \n",
    "        \n",
    "        patient_bounding_boxes_dict[\"x_min\"].append(x_min)\n",
    "        patient_bounding_boxes_dict[\"y_min\"].append(y_min)\n",
    "        patient_bounding_boxes_dict[\"z_min\"].append(z_min)\n",
    "        patient_bounding_boxes_dict[\"x_max\"].append(x_max)\n",
    "        patient_bounding_boxes_dict[\"y_max\"].append(y_max)\n",
    "        patient_bounding_boxes_dict[\"z_max\"].append(z_max)\n",
    "\n",
    "patient_bounding_boxes = pd.DataFrame.from_dict(patient_bounding_boxes_dict)\n",
    "patient_bounding_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d871f5",
   "metadata": {
    "papermill": {
     "duration": 0.014307,
     "end_time": "2024-09-30T17:04:37.568011",
     "exception": false,
     "start_time": "2024-09-30T17:04:37.553704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Stage 2: Run inference on individual vertebrae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b0237",
   "metadata": {
    "papermill": {
     "duration": 0.014418,
     "end_time": "2024-09-30T17:04:37.597951",
     "exception": false,
     "start_time": "2024-09-30T17:04:37.583533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcb1ea49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:37.628734Z",
     "iopub.status.busy": "2024-09-30T17:04:37.628359Z",
     "iopub.status.idle": "2024-09-30T17:04:37.633829Z",
     "shell.execute_reply": "2024-09-30T17:04:37.632911Z"
    },
    "papermill": {
     "duration": 0.023331,
     "end_time": "2024-09-30T17:04:37.635813",
     "exception": false,
     "start_time": "2024-09-30T17:04:37.612482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def retrieve_image_paths(base_path, study_id, series_id):\n",
    "    series_dir = os.path.join(base_path, str(study_id), str(series_id))\n",
    "    images = os.listdir(series_dir)\n",
    "    image_paths = [os.path.join(series_dir, img) for img in images]\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fbc25f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:37.665675Z",
     "iopub.status.busy": "2024-09-30T17:04:37.665340Z",
     "iopub.status.idle": "2024-09-30T17:04:38.746977Z",
     "shell.execute_reply": "2024-09-30T17:04:38.746221Z"
    },
    "papermill": {
     "duration": 1.099071,
     "end_time": "2024-09-30T17:04:38.749148",
     "exception": false,
     "start_time": "2024-09-30T17:04:37.650077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import pgzip\n",
    "import os\n",
    "\n",
    "def read_vertebral_levels_as_voxel_grids(dir_path,\n",
    "                                         vertebral_levels: list[str],\n",
    "                                         max_bounds: list[np.array],\n",
    "                                         min_bounds: list[np.array],\n",
    "                                         pcd_overall: o3d.geometry.PointCloud = None,\n",
    "                                         cache_basepath=\"/kaggle/working/cached_3d\",\n",
    "                                         series_type_dict=None,\n",
    "                                         downsampling_factor=1,\n",
    "                                         voxel_size=(128, 128, 42),\n",
    "                                        caching=False):\n",
    "    ret = {}\n",
    "    \n",
    "    resize = tio.Resize(voxel_size)\n",
    "\n",
    "    if pcd_overall is None:\n",
    "        pcd_overall = read_study_as_pcd(dir_path,\n",
    "                                        series_types_dict=series_type_dict,\n",
    "                                        downsampling_factor=downsampling_factor,\n",
    "                                        img_size=(voxel_size[0], voxel_size[2]),\n",
    "                                        stack_slices_thickness=True,\n",
    "                                        resize_slices=False)\n",
    "\n",
    "    \n",
    "    for index, vertebral_level in enumerate(vertebral_levels):\n",
    "            bbox = o3d.geometry.AxisAlignedBoundingBox(min_bound=min_bounds[index], max_bound=max_bounds[index])\n",
    "            pcd_level = pcd_overall.crop(bbox)\n",
    "\n",
    "            size = 1\n",
    "            voxel_level = o3d.geometry.VoxelGrid().create_from_point_cloud(pcd_level, size,\n",
    "                                                                           color_mode=o3d.geometry.VoxelGrid.VoxelColorMode.MAX)\n",
    "\n",
    "            coords = np.array([voxel.grid_index for voxel in voxel_level.get_voxels()])\n",
    "            vals = np.array([voxel.color for voxel in voxel_level.get_voxels()], dtype=np.float16)\n",
    "\n",
    "            size = np.max(coords, axis=0) + 1\n",
    "            grid = np.zeros((3, size[0], size[1], size[2]), dtype=np.float32)\n",
    "            indices = coords[:, 0], coords[:, 1], coords[:, 2]\n",
    "\n",
    "            for i in range(3):\n",
    "                grid[i][indices] = vals[:, i]\n",
    "\n",
    "            grid = resize(grid)\n",
    "\n",
    "            ret[vertebral_level] = grid\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c7ea741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:38.780097Z",
     "iopub.status.busy": "2024-09-30T17:04:38.779152Z",
     "iopub.status.idle": "2024-09-30T17:04:38.800730Z",
     "shell.execute_reply": "2024-09-30T17:04:38.799938Z"
    },
    "papermill": {
     "duration": 0.038958,
     "end_time": "2024-09-30T17:04:38.802618",
     "exception": false,
     "start_time": "2024-09-30T17:04:38.763660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_study_as_pcd(dir_path,\n",
    "                      series_types_dict=None,\n",
    "                      downsampling_factor=1,\n",
    "                      resize_slices=True,\n",
    "                      resize_method=\"nearest\",\n",
    "                      stack_slices_thickness=True,\n",
    "                      img_size=(256, 256)):\n",
    "    pcd_overall = o3d.geometry.PointCloud()\n",
    "\n",
    "    for path in glob.glob(os.path.join(dir_path, \"**/*.dcm\"), recursive=True):\n",
    "        dicom_slice = dcmread(path)\n",
    "\n",
    "        series_id = os.path.basename(os.path.dirname(path))\n",
    "        study_id = os.path.basename(os.path.dirname(os.path.dirname(path)))\n",
    "        if series_types_dict is None or int(series_id) not in series_types_dict:\n",
    "            series_desc = dicom_slice.SeriesDescription\n",
    "        else:\n",
    "            series_desc = series_types_dict[int(series_id)]\n",
    "            series_desc = series_desc.split(\" \")[-1]\n",
    "\n",
    "        x_orig, y_orig = dicom_slice.pixel_array.shape\n",
    "        if resize_slices:\n",
    "            if resize_method == \"nearest\":\n",
    "                img = np.expand_dims(cv2.resize(dicom_slice.pixel_array, img_size, interpolation=cv2.INTER_AREA), -1)\n",
    "            elif resize_method == \"maxpool\":\n",
    "                img_tensor = torch.tensor(dicom_slice.pixel_array).float()\n",
    "                img = F.adaptive_max_pool2d(img_tensor.unsqueeze(0), img_size).numpy()\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid resize_method {resize_method}\")\n",
    "        else:\n",
    "            img = np.expand_dims(np.array(dicom_slice.pixel_array), -1)\n",
    "        x, y, z = np.where(img)\n",
    "\n",
    "        downsampling_factor_iter = max(downsampling_factor, int(math.ceil(len(x) / 6e6)))\n",
    "\n",
    "        index_voxel = np.vstack((x, y, z))[:, ::downsampling_factor_iter]\n",
    "        grid_index_array = index_voxel.T\n",
    "        pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(grid_index_array.astype(np.float64)))\n",
    "\n",
    "        vals = np.expand_dims(img[x, y, z][::downsampling_factor_iter], -1)\n",
    "        if series_desc == \"T1\":\n",
    "            vals = np.pad(vals, ((0, 0), (0, 2)))\n",
    "        elif series_desc == \"T2\":\n",
    "            vals = np.pad(vals, ((0, 0), (1, 1)))\n",
    "        elif series_desc == \"T2/STIR\":\n",
    "            vals = np.pad(vals, ((0, 0), (2, 0)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown series desc: {series_desc}\")\n",
    "\n",
    "        pcd.colors = o3d.utility.Vector3dVector(vals.astype(np.float64))\n",
    "\n",
    "        if resize_slices:\n",
    "            transform_matrix_factor = np.matrix(\n",
    "                [[0, y_orig / img_size[1], 0, 0],\n",
    "                 [x_orig / img_size[0], 0, 0, 0],\n",
    "                 [0, 0, 1, 0],\n",
    "                 [0, 0, 0, 1]]\n",
    "            )\n",
    "        else:\n",
    "            transform_matrix_factor = np.matrix(\n",
    "                [[0, 1, 0, 0],\n",
    "                 [1, 0, 0, 0],\n",
    "                 [0, 0, 1, 0],\n",
    "                 [0, 0, 0, 1]]\n",
    "            )\n",
    "\n",
    "        dX, dY = dicom_slice.PixelSpacing\n",
    "        dZ = dicom_slice.SliceThickness\n",
    "\n",
    "        X = np.array(list(dicom_slice.ImageOrientationPatient[:3]) + [0]) * dX\n",
    "        Y = np.array(list(dicom_slice.ImageOrientationPatient[3:]) + [0]) * dY\n",
    "\n",
    "        S = np.array(list(dicom_slice.ImagePositionPatient) + [1])\n",
    "\n",
    "        transform_matrix = np.array([X, Y, np.zeros(len(X)), S]).T\n",
    "        transform_matrix = transform_matrix @ transform_matrix_factor\n",
    "\n",
    "        if stack_slices_thickness:\n",
    "            for z in range(int(dZ)):\n",
    "                pos = list(dicom_slice.ImagePositionPatient)\n",
    "                if series_desc == \"T2\":\n",
    "                    pos[-1] += z\n",
    "                else:\n",
    "                    pos[0] += z\n",
    "                S = np.array(pos + [1])\n",
    "\n",
    "                transform_matrix = np.array([X, Y, np.zeros(len(X)), S]).T\n",
    "                transform_matrix = transform_matrix @ transform_matrix_factor\n",
    "\n",
    "                pcd_overall += copy.deepcopy(pcd).transform(transform_matrix)\n",
    "\n",
    "        else:\n",
    "            pcd_overall += copy.deepcopy(pcd).transform(transform_matrix)\n",
    "\n",
    "    return pcd_overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4dd687f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:38.833541Z",
     "iopub.status.busy": "2024-09-30T17:04:38.832728Z",
     "iopub.status.idle": "2024-09-30T17:04:39.435515Z",
     "shell.execute_reply": "2024-09-30T17:04:39.434657Z"
    },
    "papermill": {
     "duration": 0.620598,
     "end_time": "2024-09-30T17:04:39.437871",
     "exception": false,
     "start_time": "2024-09-30T17:04:38.817273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchio as tio\n",
    "import torch.nn as nn\n",
    "import pydicom\n",
    "\n",
    "CONDITIONS = {\n",
    "    \"Sagittal T2/STIR\": [\"Spinal Canal Stenosis\"],\n",
    "    \"Axial T2\": [\"Left Subarticular Stenosis\", \"Right Subarticular Stenosis\"],\n",
    "    \"Sagittal T1\": [\"Left Neural Foraminal Narrowing\", \"Right Neural Foraminal Narrowing\"],\n",
    "}\n",
    "\n",
    "LEVELS = [\"l1_l2\", \"l2_l3\", \"l3_l4\", \"l4_l5\", \"l5_s1\"]\n",
    "\n",
    "class StudyPerVertebraLevelDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 base_path: str,\n",
    "                 dataframe: pd.DataFrame,\n",
    "                 bounds_dataframe: pd.DataFrame,\n",
    "                 transform_3d=None,\n",
    "                 vol_size=(128, 128, 128)\n",
    "                ):\n",
    "        self.base_path = base_path\n",
    "\n",
    "        self.dataframe = (dataframe[['study_id', \"series_id\", \"series_description\"]]\n",
    "                          .drop_duplicates())\n",
    "        self.bounds_dataframe = bounds_dataframe\n",
    "\n",
    "        self.subjects = self.dataframe[['study_id']].drop_duplicates().reset_index(drop=True)\n",
    "        self.series = self.dataframe[[\"study_id\", \"series_id\"]].drop_duplicates().groupby(\"study_id\")[\n",
    "            \"series_id\"].apply(list).to_dict()\n",
    "        self.series_descs = {e[0]: e[1] for e in\n",
    "                             self.dataframe[[\"series_id\", \"series_description\"]].drop_duplicates().values}\n",
    "\n",
    "        self.transform_3d = transform_3d\n",
    "        self.vol_size = vol_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        curr = self.subjects.iloc[index % len(self.subjects)]\n",
    "\n",
    "        study_path = os.path.join(self.base_path, str(curr[\"study_id\"]))\n",
    "        \n",
    "        curr_bounds = self.bounds_dataframe[self.bounds_dataframe[\"study_id\"] == curr[\"study_id\"]].sort_values(by=\"level\")\n",
    "        \n",
    "        study_images = read_vertebral_levels_as_voxel_grids(study_path,\n",
    "                                                      vertebral_levels=LEVELS,\n",
    "                                                      min_bounds=np.array(curr_bounds[['x_min', 'y_min', 'z_min']].values),\n",
    "                                                      max_bounds=np.array(curr_bounds[['x_max', 'y_max', 'z_max']].values),\n",
    "                                                      series_type_dict=self.series_descs,\n",
    "                                                      voxel_size=self.vol_size\n",
    "                                                    )\n",
    "        \n",
    "        ret = []\n",
    "        for level in LEVELS:\n",
    "            image = study_images[level]\n",
    "            image = torch.FloatTensor(image)\n",
    "            image = self.transform_3d(image)\n",
    "            ret.append(image.to(torch.half))\n",
    "            \n",
    "        return torch.stack(ret), curr[\"study_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06571fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:39.468282Z",
     "iopub.status.busy": "2024-09-30T17:04:39.467903Z",
     "iopub.status.idle": "2024-09-30T17:04:39.472504Z",
     "shell.execute_reply": "2024-09-30T17:04:39.471618Z"
    },
    "papermill": {
     "duration": 0.021911,
     "end_time": "2024-09-30T17:04:39.474350",
     "exception": false,
     "start_time": "2024-09-30T17:04:39.452439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_3d = tio.Compose([\n",
    "    tio.RescaleIntensity([0, 1]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8edcf7b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:39.504399Z",
     "iopub.status.busy": "2024-09-30T17:04:39.504062Z",
     "iopub.status.idle": "2024-09-30T17:04:39.509861Z",
     "shell.execute_reply": "2024-09-30T17:04:39.509015Z"
    },
    "papermill": {
     "duration": 0.023136,
     "end_time": "2024-09-30T17:04:39.511797",
     "exception": false,
     "start_time": "2024-09-30T17:04:39.488661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_subject_level_testset_and_loader(df: pd.DataFrame,\n",
    "                                             transform_3d,\n",
    "                                             base_path: str,\n",
    "                                             batch_size=1,\n",
    "                                             num_workers=4):\n",
    "    testset = StudyPerVertebraLevelDataset(base_path=test_images_basepath, dataframe=df, bounds_dataframe=patient_bounding_boxes, transform_3d=transform_3d)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return testset, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cab87518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:39.542264Z",
     "iopub.status.busy": "2024-09-30T17:04:39.541533Z",
     "iopub.status.idle": "2024-09-30T17:04:39.558364Z",
     "shell.execute_reply": "2024-09-30T17:04:39.557335Z"
    },
    "papermill": {
     "duration": 0.034271,
     "end_time": "2024-09-30T17:04:39.560398",
     "exception": false,
     "start_time": "2024-09-30T17:04:39.526127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_descs_valid = test_descs[test_descs[\"study_id\"].isin(patient_bounding_boxes[\"study_id\"])]\n",
    "\n",
    "testset, test_loader = create_subject_level_testset_and_loader(test_descs_valid, transform_3d, test_images_basepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4962d9f1",
   "metadata": {
    "papermill": {
     "duration": 0.014268,
     "end_time": "2024-09-30T17:04:39.589067",
     "exception": false,
     "start_time": "2024-09-30T17:04:39.574799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "889504fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:39.619517Z",
     "iopub.status.busy": "2024-09-30T17:04:39.618889Z",
     "iopub.status.idle": "2024-09-30T17:04:48.901940Z",
     "shell.execute_reply": "2024-09-30T17:04:48.900928Z"
    },
    "papermill": {
     "duration": 9.300719,
     "end_time": "2024-09-30T17:04:48.904127",
     "exception": false,
     "start_time": "2024-09-30T17:04:39.603408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/tmp/ipykernel_23/2930394370.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/input/rsna_2024_stage_2/pytorch/coatnet_rmlp_3_224_128/9/coatnet_rmlp_3_rw_128_vertebrae_tuned_fold_0_2.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm_3d\n",
    "import torch\n",
    "\n",
    "from spacecutter.losses import CumulativeLinkLoss\n",
    "from spacecutter.models import LogisticCumulativeLink\n",
    "from spacecutter.callbacks import AscensionCallback\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class CustomMaxxVit3dClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone,\n",
    "                 in_chans=3,\n",
    "                 out_classes=5,\n",
    "                 cutpoint_margin=0):\n",
    "        super(CustomMaxxVit3dClassifier, self).__init__()\n",
    "        self.out_classes = out_classes\n",
    "\n",
    "        self.config = timm_3d.models.maxxvit.model_cfgs[backbone]\n",
    "\n",
    "        self.backbone = timm_3d.models.MaxxVit(\n",
    "            img_size=(128,128,128),\n",
    "            in_chans=in_chans,\n",
    "            num_classes=out_classes,\n",
    "            drop_rate=0,\n",
    "            drop_path_rate=0,\n",
    "            cfg=self.config\n",
    "        )\n",
    "        self.backbone.head.drop = nn.Dropout(0)\n",
    "        head_in_dim = self.backbone.head.fc.in_features\n",
    "        self.backbone.head.fc = nn.Identity()\n",
    "\n",
    "        self.heads = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Linear(head_in_dim, 1),\n",
    "                LogisticCumulativeLink(3)\n",
    "            ) for i in range(out_classes)]\n",
    "        )\n",
    "\n",
    "        self.ascension_callback = AscensionCallback(margin=cutpoint_margin)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        return torch.swapaxes(torch.stack([head(feat) for head in self.heads]), 0, 1)\n",
    "\n",
    "    def _ascension_callback(self):\n",
    "        for head in self.heads:\n",
    "            self.ascension_callback.clip(head[-1])\n",
    "\n",
    "model = CustomMaxxVit3dClassifier(backbone=\"coatnet_rmlp_3_rw\", in_chans=3, out_classes=5).to(device)\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/rsna_2024_stage_2/pytorch/coatnet_rmlp_3_224_128/9/coatnet_rmlp_3_rw_128_vertebrae_tuned_fold_0_2.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2016be42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:48.935716Z",
     "iopub.status.busy": "2024-09-30T17:04:48.934811Z",
     "iopub.status.idle": "2024-09-30T17:04:48.943629Z",
     "shell.execute_reply": "2024-09-30T17:04:48.942805Z"
    },
    "papermill": {
     "duration": 0.02642,
     "end_time": "2024-09-30T17:04:48.945535",
     "exception": false,
     "start_time": "2024-09-30T17:04:48.919115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left_neural_foraminal_narrowing',\n",
       " 'left_subarticular_stenosis',\n",
       " 'right_neural_foraminal_narrowing',\n",
       " 'right_subarticular_stenosis',\n",
       " 'spinal_canal_stenosis']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONDITIONS = {\n",
    "    \"Sagittal T2/STIR\": [\"spinal_canal_stenosis\"],\n",
    "    \"Axial T2\": [\"left_subarticular_stenosis\", \"right_subarticular_stenosis\"],\n",
    "    \"Sagittal T1\": [\"left_neural_foraminal_narrowing\", \"right_neural_foraminal_narrowing\"],\n",
    "}\n",
    "\n",
    "ALL_CONDITIONS = sorted([\"spinal_canal_stenosis\", \"left_subarticular_stenosis\", \"right_subarticular_stenosis\", \"left_neural_foraminal_narrowing\", \"right_neural_foraminal_narrowing\"])\n",
    "LEVELS = [\"l1_l2\", \"l2_l3\", \"l3_l4\", \"l4_l5\", \"l5_s1\"]\n",
    "\n",
    "results_df = pd.DataFrame({\"row_id\":[], \"normal_mild\": [], \"moderate\": [], \"severe\": []})\n",
    "\n",
    "ALL_CONDITIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8af11a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:48.976373Z",
     "iopub.status.busy": "2024-09-30T17:04:48.976004Z",
     "iopub.status.idle": "2024-09-30T17:04:49.007841Z",
     "shell.execute_reply": "2024-09-30T17:04:49.007077Z"
    },
    "papermill": {
     "duration": 0.049608,
     "end_time": "2024-09-30T17:04:49.009901",
     "exception": false,
     "start_time": "2024-09-30T17:04:48.960293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-populate results df\n",
    "import glob\n",
    "import os\n",
    "\n",
    "study_ids = glob.glob(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/*\")\n",
    "study_ids = [os.path.basename(e) for e in study_ids]\n",
    "\n",
    "results_df = pd.DataFrame({\"row_id\":[], \"normal_mild\": [], \"moderate\": [], \"severe\": []})\n",
    "for study_id in study_ids:\n",
    "    for condition in ALL_CONDITIONS:\n",
    "        for level in LEVELS:\n",
    "            row_id = f\"{study_id}_{condition}_{level}\"\n",
    "            results_df = results_df._append({\"row_id\": row_id, \"normal_mild\": 1/3, \"moderate\": 1/3, \"severe\": 1/3}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97f2e436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:04:49.041706Z",
     "iopub.status.busy": "2024-09-30T17:04:49.040888Z",
     "iopub.status.idle": "2024-09-30T17:05:55.527880Z",
     "shell.execute_reply": "2024-09-30T17:05:55.526842Z"
    },
    "papermill": {
     "duration": 66.519813,
     "end_time": "2024-09-30T17:05:55.544786",
     "exception": false,
     "start_time": "2024-09-30T17:04:49.024973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2429732810.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 66.4759669303894 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "import time\n",
    "import copy\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "visualize_mid_slices = False\n",
    "\n",
    "with torch.no_grad():\n",
    "    with autocast(dtype=torch.float16):\n",
    "        model.eval()\n",
    "\n",
    "        for images, study_id in test_loader:\n",
    "            output = model(images.squeeze(0).to(device))\n",
    "            for level_index, image in enumerate(images.squeeze(0)):\n",
    "                if visualize_mid_slices:\n",
    "                    plt.imshow(np.max(image.numpy()[1, :, :, 62:66], axis=2), cmap=\"gray\")\n",
    "                    plt.show()\n",
    "                for condition_index, condition_out in enumerate(output[level_index]):\n",
    "                    row_id = f\"{study_id[0]}_{ALL_CONDITIONS[condition_index]}_{LEVELS[level_index]}\"\n",
    "                    \n",
    "                    results_df.loc[results_df.row_id == row_id, 'normal_mild'] = condition_out.cpu().numpy()[0]\n",
    "                    results_df.loc[results_df.row_id == row_id, 'moderate'] = condition_out.cpu().numpy()[1]\n",
    "                    results_df.loc[results_df.row_id == row_id, 'severe'] = condition_out.cpu().numpy()[2]\n",
    "                \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a766ae12",
   "metadata": {
    "papermill": {
     "duration": 0.014841,
     "end_time": "2024-09-30T17:05:55.574754",
     "exception": false,
     "start_time": "2024-09-30T17:05:55.559913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Stage 2.5: Run inference on the fallback set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b40976",
   "metadata": {
    "papermill": {
     "duration": 0.015678,
     "end_time": "2024-09-30T17:05:55.605567",
     "exception": false,
     "start_time": "2024-09-30T17:05:55.589889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02dfa357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:05:55.638504Z",
     "iopub.status.busy": "2024-09-30T17:05:55.638086Z",
     "iopub.status.idle": "2024-09-30T17:05:55.648429Z",
     "shell.execute_reply": "2024-09-30T17:05:55.647465Z"
    },
    "papermill": {
     "duration": 0.029292,
     "end_time": "2024-09-30T17:05:55.650567",
     "exception": false,
     "start_time": "2024-09-30T17:05:55.621275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_study_as_voxel_grid(dir_path, series_type_dict=None, downsampling_factor=1, img_size=(256, 256)):\n",
    "    pcd_overall = read_study_as_pcd(dir_path,\n",
    "                                    series_types_dict=series_type_dict,\n",
    "                                    downsampling_factor=downsampling_factor,\n",
    "                                    img_size=img_size)\n",
    "    box = pcd_overall.get_axis_aligned_bounding_box()\n",
    "\n",
    "    max_b = np.array(box.get_max_bound())\n",
    "    min_b = np.array(box.get_min_bound())\n",
    "\n",
    "    pts = (np.array(pcd_overall.points) - (min_b)) * (\n",
    "                (img_size[0] - 1, img_size[0] - 1, img_size[0] - 1) / (max_b - min_b))\n",
    "    coords = np.round(pts).astype(np.int32)\n",
    "    vals = np.array(pcd_overall.colors, dtype=np.float16)\n",
    "\n",
    "    grid = np.zeros((3, img_size[0], img_size[0], img_size[0]), dtype=np.float16)\n",
    "    indices = coords[:, 0], coords[:, 1], coords[:, 2]\n",
    "\n",
    "    np.maximum.at(grid[0], indices, vals[:, 0])\n",
    "    np.maximum.at(grid[1], indices, vals[:, 1])\n",
    "    np.maximum.at(grid[2], indices, vals[:, 2])\n",
    "\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "986ead40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:05:55.730956Z",
     "iopub.status.busy": "2024-09-30T17:05:55.730570Z",
     "iopub.status.idle": "2024-09-30T17:05:55.739980Z",
     "shell.execute_reply": "2024-09-30T17:05:55.739088Z"
    },
    "papermill": {
     "duration": 0.027977,
     "end_time": "2024-09-30T17:05:55.741898",
     "exception": false,
     "start_time": "2024-09-30T17:05:55.713921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PatientLevelTestset(Dataset):\n",
    "    def __init__(self,\n",
    "                 base_path: str,\n",
    "                 dataframe: pd.DataFrame,\n",
    "                 transform_3d=None):\n",
    "        self.base_path = base_path\n",
    "\n",
    "        self.dataframe = (dataframe[['study_id', \"series_id\", \"series_description\"]]\n",
    "                          .drop_duplicates())\n",
    "\n",
    "        self.subjects = self.dataframe[['study_id']].drop_duplicates().reset_index(drop=True)\n",
    "        self.series_descs = {e[0]: e[1] for e in self.dataframe[[\"series_id\", \"series_description\"]].drop_duplicates().values}\n",
    "\n",
    "        self.transform_3d = transform_3d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        curr = self.subjects.iloc[index]\n",
    "        study_path = os.path.join(self.base_path, str(curr[\"study_id\"]))\n",
    "\n",
    "        study_images = read_study_as_voxel_grid(study_path, self.series_descs)\n",
    "\n",
    "        if self.transform_3d is not None:\n",
    "            study_images = self.transform_3d(torch.FloatTensor(study_images))\n",
    "            return study_images.to(torch.half), str(curr[\"study_id\"])\n",
    "\n",
    "        return torch.HalfTensor(study_images), str(curr[\"study_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a870e49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:05:55.773664Z",
     "iopub.status.busy": "2024-09-30T17:05:55.773285Z",
     "iopub.status.idle": "2024-09-30T17:05:55.778887Z",
     "shell.execute_reply": "2024-09-30T17:05:55.778067Z"
    },
    "papermill": {
     "duration": 0.023824,
     "end_time": "2024-09-30T17:05:55.780921",
     "exception": false,
     "start_time": "2024-09-30T17:05:55.757097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_subject_level_fallback_testset_and_loader(df: pd.DataFrame,\n",
    "                                             transform_3d,\n",
    "                                             base_path: str,\n",
    "                                             batch_size=1,\n",
    "                                             num_workers=4):\n",
    "    testset = PatientLevelTestset(base_path, df, transform_3d=transform_3d)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return testset, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b26f0a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:05:55.812731Z",
     "iopub.status.busy": "2024-09-30T17:05:55.812139Z",
     "iopub.status.idle": "2024-09-30T17:05:55.821932Z",
     "shell.execute_reply": "2024-09-30T17:05:55.820984Z"
    },
    "papermill": {
     "duration": 0.027981,
     "end_time": "2024-09-30T17:05:55.824128",
     "exception": false,
     "start_time": "2024-09-30T17:05:55.796147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_descs_invalid = test_descs[~test_descs[\"study_id\"].isin(patient_bounding_boxes[\"study_id\"])]\n",
    "testset_fallback, test_loader_fallback = create_subject_level_fallback_testset_and_loader(test_descs_invalid, transform_3d, test_images_basepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c107f5",
   "metadata": {
    "papermill": {
     "duration": 0.014715,
     "end_time": "2024-09-30T17:05:55.854912",
     "exception": false,
     "start_time": "2024-09-30T17:05:55.840197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67ca2cff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:05:55.886461Z",
     "iopub.status.busy": "2024-09-30T17:05:55.886069Z",
     "iopub.status.idle": "2024-09-30T17:05:55.897015Z",
     "shell.execute_reply": "2024-09-30T17:05:55.896010Z"
    },
    "papermill": {
     "duration": 0.029273,
     "end_time": "2024-09-30T17:05:55.899130",
     "exception": false,
     "start_time": "2024-09-30T17:05:55.869857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_Model_3D_Multihead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone=\"efficientnet_lite0\",\n",
    "                 in_chans=1,\n",
    "                 out_classes=5,\n",
    "                 cutpoint_margin=0.15,\n",
    "                 pretrained=False):\n",
    "        super(CNN_Model_3D_Multihead, self).__init__()\n",
    "        self.out_classes = out_classes\n",
    "\n",
    "        self.encoder = timm_3d.create_model(\n",
    "            backbone,\n",
    "            features_only=False,\n",
    "            drop_rate=0,\n",
    "            drop_path_rate=0,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=in_chans,\n",
    "            global_pool=\"max\"\n",
    "        )\n",
    "        if \"efficientnet\" in backbone:\n",
    "            head_in_dim = self.encoder.classifier.in_features\n",
    "            self.encoder.classifier = nn.Sequential(\n",
    "                nn.LayerNorm(head_in_dim),\n",
    "                nn.Dropout(0),\n",
    "            )\n",
    "\n",
    "        elif \"vit\" in backbone:\n",
    "            self.encoder.head.drop = nn.Dropout(0)\n",
    "            head_in_dim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "        self.heads = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Linear(head_in_dim, 1),\n",
    "                LogisticCumulativeLink(3)\n",
    "            ) for i in range(out_classes)]\n",
    "        )\n",
    "\n",
    "        self.ascension_callback = AscensionCallback(margin=cutpoint_margin)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.encoder(x)\n",
    "        return torch.swapaxes(torch.stack([head(feat) for head in self.heads]), 0, 1)\n",
    "\n",
    "    def _ascension_callback(self):\n",
    "        for head in self.heads:\n",
    "            self.ascension_callback.clip(head[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "535db572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:05:55.931146Z",
     "iopub.status.busy": "2024-09-30T17:05:55.930739Z",
     "iopub.status.idle": "2024-09-30T17:05:58.078989Z",
     "shell.execute_reply": "2024-09-30T17:05:58.078061Z"
    },
    "papermill": {
     "duration": 2.166783,
     "end_time": "2024-09-30T17:05:58.081162",
     "exception": false,
     "start_time": "2024-09-30T17:05:55.914379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/186658774.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  fallback_model.load_state_dict(torch.load(\"/kaggle/input/rsna-2024/pytorch/vit_voxel_v2/7/maxvit_rmlp_tiny_rw_256_256_v2_fold_3_32.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fallback_model = CNN_Model_3D_Multihead(backbone=\"maxvit_rmlp_tiny_rw_256\", in_chans=3, out_classes=25).to(device)\n",
    "fallback_model.load_state_dict(torch.load(\"/kaggle/input/rsna-2024/pytorch/vit_voxel_v2/7/maxvit_rmlp_tiny_rw_256_256_v2_fold_3_32.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e5b2ca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:05:58.113705Z",
     "iopub.status.busy": "2024-09-30T17:05:58.113058Z",
     "iopub.status.idle": "2024-09-30T17:05:58.281893Z",
     "shell.execute_reply": "2024-09-30T17:05:58.280516Z"
    },
    "papermill": {
     "duration": 0.187418,
     "end_time": "2024-09-30T17:05:58.284135",
     "exception": false,
     "start_time": "2024-09-30T17:05:58.096717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/421822995.py:6: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.1591629981994629 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    with autocast(dtype=torch.float16):\n",
    "        fallback_model.eval()\n",
    "\n",
    "        for images, study_id in test_loader_fallback:\n",
    "            output = fallback_model(images.to(device))\n",
    "            for i, batch_out in enumerate(output):\n",
    "                batch_out = output.cpu().numpy()[i]\n",
    "                for index, level in enumerate(batch_out):\n",
    "                    row_id = f\"{study_id[i]}_{ALL_CONDITIONS[index // 5]}_{LEVELS[index % 5]}\"\n",
    "                    results_df.loc[results_df.row_id == row_id,'normal_mild'] = level[0]\n",
    "                    results_df.loc[results_df.row_id == row_id,'moderate'] = level[1]\n",
    "                    results_df.loc[results_df.row_id == row_id,'severe'] = level[2]\n",
    "                \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a636b12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:05:58.318735Z",
     "iopub.status.busy": "2024-09-30T17:05:58.317659Z",
     "iopub.status.idle": "2024-09-30T17:05:58.334819Z",
     "shell.execute_reply": "2024-09-30T17:05:58.333911Z"
    },
    "papermill": {
     "duration": 0.036612,
     "end_time": "2024-09-30T17:05:58.336808",
     "exception": false,
     "start_time": "2024-09-30T17:05:58.300196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>normal_mild</th>\n",
       "      <th>moderate</th>\n",
       "      <th>severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.982586</td>\n",
       "      <td>0.017113</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.390407</td>\n",
       "      <td>0.583738</td>\n",
       "      <td>0.025856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.022515</td>\n",
       "      <td>0.552866</td>\n",
       "      <td>0.424619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.334560</td>\n",
       "      <td>0.656629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.148875</td>\n",
       "      <td>0.762552</td>\n",
       "      <td>0.088573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l1_l2</td>\n",
       "      <td>0.412234</td>\n",
       "      <td>0.514634</td>\n",
       "      <td>0.073132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l2_l3</td>\n",
       "      <td>0.070129</td>\n",
       "      <td>0.506652</td>\n",
       "      <td>0.423220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l3_l4</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>0.338817</td>\n",
       "      <td>0.629661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l4_l5</td>\n",
       "      <td>0.030380</td>\n",
       "      <td>0.331123</td>\n",
       "      <td>0.638497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l5_s1</td>\n",
       "      <td>0.011912</td>\n",
       "      <td>0.166972</td>\n",
       "      <td>0.821116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.603368</td>\n",
       "      <td>0.384305</td>\n",
       "      <td>0.012326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.374696</td>\n",
       "      <td>0.594594</td>\n",
       "      <td>0.030710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.431486</td>\n",
       "      <td>0.544111</td>\n",
       "      <td>0.024404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.180336</td>\n",
       "      <td>0.740228</td>\n",
       "      <td>0.079436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.033371</td>\n",
       "      <td>0.611823</td>\n",
       "      <td>0.354806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l1_l2</td>\n",
       "      <td>0.131799</td>\n",
       "      <td>0.607409</td>\n",
       "      <td>0.260792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l2_l3</td>\n",
       "      <td>0.107898</td>\n",
       "      <td>0.585192</td>\n",
       "      <td>0.306910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l3_l4</td>\n",
       "      <td>0.240237</td>\n",
       "      <td>0.614918</td>\n",
       "      <td>0.144845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l4_l5</td>\n",
       "      <td>0.154630</td>\n",
       "      <td>0.618884</td>\n",
       "      <td>0.226487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l5_s1</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.074207</td>\n",
       "      <td>0.921235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l1_l2</td>\n",
       "      <td>0.630511</td>\n",
       "      <td>0.355762</td>\n",
       "      <td>0.013727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l2_l3</td>\n",
       "      <td>0.169438</td>\n",
       "      <td>0.726279</td>\n",
       "      <td>0.104283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l3_l4</td>\n",
       "      <td>0.702374</td>\n",
       "      <td>0.287662</td>\n",
       "      <td>0.009964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l4_l5</td>\n",
       "      <td>0.483705</td>\n",
       "      <td>0.491570</td>\n",
       "      <td>0.024724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l5_s1</td>\n",
       "      <td>0.206131</td>\n",
       "      <td>0.710063</td>\n",
       "      <td>0.083805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             row_id  normal_mild  moderate  \\\n",
       "0    44036939_left_neural_foraminal_narrowing_l1_l2     0.982586  0.017113   \n",
       "1    44036939_left_neural_foraminal_narrowing_l2_l3     0.390407  0.583738   \n",
       "2    44036939_left_neural_foraminal_narrowing_l3_l4     0.022515  0.552866   \n",
       "3    44036939_left_neural_foraminal_narrowing_l4_l5     0.008811  0.334560   \n",
       "4    44036939_left_neural_foraminal_narrowing_l5_s1     0.148875  0.762552   \n",
       "5         44036939_left_subarticular_stenosis_l1_l2     0.412234  0.514634   \n",
       "6         44036939_left_subarticular_stenosis_l2_l3     0.070129  0.506652   \n",
       "7         44036939_left_subarticular_stenosis_l3_l4     0.031522  0.338817   \n",
       "8         44036939_left_subarticular_stenosis_l4_l5     0.030380  0.331123   \n",
       "9         44036939_left_subarticular_stenosis_l5_s1     0.011912  0.166972   \n",
       "10  44036939_right_neural_foraminal_narrowing_l1_l2     0.603368  0.384305   \n",
       "11  44036939_right_neural_foraminal_narrowing_l2_l3     0.374696  0.594594   \n",
       "12  44036939_right_neural_foraminal_narrowing_l3_l4     0.431486  0.544111   \n",
       "13  44036939_right_neural_foraminal_narrowing_l4_l5     0.180336  0.740228   \n",
       "14  44036939_right_neural_foraminal_narrowing_l5_s1     0.033371  0.611823   \n",
       "15       44036939_right_subarticular_stenosis_l1_l2     0.131799  0.607409   \n",
       "16       44036939_right_subarticular_stenosis_l2_l3     0.107898  0.585192   \n",
       "17       44036939_right_subarticular_stenosis_l3_l4     0.240237  0.614918   \n",
       "18       44036939_right_subarticular_stenosis_l4_l5     0.154630  0.618884   \n",
       "19       44036939_right_subarticular_stenosis_l5_s1     0.004558  0.074207   \n",
       "20             44036939_spinal_canal_stenosis_l1_l2     0.630511  0.355762   \n",
       "21             44036939_spinal_canal_stenosis_l2_l3     0.169438  0.726279   \n",
       "22             44036939_spinal_canal_stenosis_l3_l4     0.702374  0.287662   \n",
       "23             44036939_spinal_canal_stenosis_l4_l5     0.483705  0.491570   \n",
       "24             44036939_spinal_canal_stenosis_l5_s1     0.206131  0.710063   \n",
       "\n",
       "      severe  \n",
       "0   0.000301  \n",
       "1   0.025856  \n",
       "2   0.424619  \n",
       "3   0.656629  \n",
       "4   0.088573  \n",
       "5   0.073132  \n",
       "6   0.423220  \n",
       "7   0.629661  \n",
       "8   0.638497  \n",
       "9   0.821116  \n",
       "10  0.012326  \n",
       "11  0.030710  \n",
       "12  0.024404  \n",
       "13  0.079436  \n",
       "14  0.354806  \n",
       "15  0.260792  \n",
       "16  0.306910  \n",
       "17  0.144845  \n",
       "18  0.226487  \n",
       "19  0.921235  \n",
       "20  0.013727  \n",
       "21  0.104283  \n",
       "22  0.009964  \n",
       "23  0.024724  \n",
       "24  0.083805  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32885885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T17:05:58.370813Z",
     "iopub.status.busy": "2024-09-30T17:05:58.369700Z",
     "iopub.status.idle": "2024-09-30T17:05:58.378499Z",
     "shell.execute_reply": "2024-09-30T17:05:58.377761Z"
    },
    "papermill": {
     "duration": 0.027728,
     "end_time": "2024-09-30T17:05:58.380408",
     "exception": false,
     "start_time": "2024-09-30T17:05:58.352680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "datasetId": 5738548,
     "sourceId": 9442803,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 196245856,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 197472610,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 197892115,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 84065,
     "modelInstanceId": 85952,
     "sourceId": 111114,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 89293,
     "modelInstanceId": 64905,
     "sourceId": 114536,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 127721,
     "modelInstanceId": 103499,
     "sourceId": 123768,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 124196,
     "modelInstanceId": 100027,
     "sourceId": 124177,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 491.958667,
   "end_time": "2024-09-30T17:06:01.267440",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-30T16:57:49.308773",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
